{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 09. Exercise 03\n",
    "# Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier, StackingClassifier\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create the same dataframe as in the previous exercise.\n",
    "2. Using `train_test_split` with parameters `test_size=0.2`, `random_state=21` get `X_train`, `y_train`, `X_test`, `y_test` and then get `X_train`, `y_train`, `X_valid`, `y_valid` from the previous `X_train`, `y_train`. Use the additional parameter `stratify`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/dayofweek-not-scaled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['dayofweek'], axis=1)\n",
    "y = df['dayofweek']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y,\n",
    "                                                    random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train,\n",
    "                                                    random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Individual classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train SVM, decision tree and random forest again with the best parameters that you got from the 01 exercise with `random_state=21` for all of them.\n",
    "2. Evaluate `accuracy`, `precision`, and `recall` for them on the validation set.\n",
    "3. The result of each cell of the section should look like this:\n",
    "\n",
    "```\n",
    "accuracy is 0.87778\n",
    "precision is 0.88162\n",
    "recall is 0.87778\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n",
      "accuracy is 0.87778\n",
      "precision is 0.88162\n",
      "recall is 0.87778\n",
      "\n",
      "Decision Tree:\n",
      "accuracy is 0.84444\n",
      "precision is 0.84596\n",
      "recall is 0.84444\n",
      "\n",
      "Random Forest:\n",
      "accuracy is 0.88889\n",
      "precision is 0.88940\n",
      "recall is 0.88889\n"
     ]
    }
   ],
   "source": [
    "# Лучшие параметры для моделей\n",
    "best_params_svm = {'kernel': 'rbf', 'C': 10.0, 'gamma': 'auto', 'probability': True, 'random_state': 21}\n",
    "best_params_dt = {'max_depth': 17, 'random_state': 21}\n",
    "best_params_rf = {'n_estimators': 100, 'max_depth': 28, 'random_state': 21}\n",
    "\n",
    "# Инициализация моделей с лучшими параметрами\n",
    "svm_model = SVC(**best_params_svm)\n",
    "dt_model = DecisionTreeClassifier(**best_params_dt)\n",
    "rf_model = RandomForestClassifier(**best_params_rf)\n",
    "\n",
    "# Обучение моделей\n",
    "svm_model.fit(X_train, y_train)\n",
    "dt_model.fit(X_train, y_train)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Прогнозирование на валидационном наборе данных\n",
    "y_val_pred_svm = svm_model.predict(X_valid)\n",
    "y_val_pred_dt = dt_model.predict(X_valid)\n",
    "y_val_pred_rf = rf_model.predict(X_valid)\n",
    "\n",
    "# Оценка метрик для SVM\n",
    "accuracy_svm = accuracy_score(y_valid, y_val_pred_svm)\n",
    "precision_svm = precision_score(y_valid, y_val_pred_svm, average='weighted')\n",
    "recall_svm = recall_score(y_valid, y_val_pred_svm, average='weighted')\n",
    "\n",
    "print(\"SVM:\")\n",
    "print(f\"accuracy is {accuracy_svm:.5f}\")\n",
    "print(f\"precision is {precision_svm:.5f}\")\n",
    "print(f\"recall is {recall_svm:.5f}\")\n",
    "print()\n",
    "\n",
    "# Оценка метрик для Decision Tree\n",
    "accuracy_dt = accuracy_score(y_valid, y_val_pred_dt)\n",
    "precision_dt = precision_score(y_valid, y_val_pred_dt, average='weighted')\n",
    "recall_dt = recall_score(y_valid, y_val_pred_dt, average='weighted')\n",
    "\n",
    "print(\"Decision Tree:\")\n",
    "print(f\"accuracy is {accuracy_dt:.5f}\")\n",
    "print(f\"precision is {precision_dt:.5f}\")\n",
    "print(f\"recall is {recall_dt:.5f}\")\n",
    "print()\n",
    "\n",
    "# Оценка метрик для Random Forest\n",
    "accuracy_rf = accuracy_score(y_valid, y_val_pred_rf)\n",
    "precision_rf = precision_score(y_valid, y_val_pred_rf, average='weighted')\n",
    "recall_rf = recall_score(y_valid, y_val_pred_rf, average='weighted')\n",
    "\n",
    "print(\"Random Forest:\")\n",
    "print(f\"accuracy is {accuracy_rf:.5f}\")\n",
    "print(f\"precision is {precision_rf:.5f}\")\n",
    "print(f\"recall is {recall_rf:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Voting classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using `VotingClassifier` and the three models that you have just trained, calculate the `accuracy`, `precision`, and `recall` on the validation set.\n",
    "2. Play with the other parameteres.\n",
    "3. Calculate the `accuracy`, `precision` and `recall` on the test set for the model with the best weights in terms of accuracy (if there are several of them with equal values, choose the one with the higher precision)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators=[\n",
    "    ('svm', svm_model),\n",
    "    ('dt', dt_model),\n",
    "    ('rfc', rf_model)]\n",
    "weights = [\n",
    "    [1, 1, 1],  # Все модели имеют одинаковый вес\n",
    "    [2, 1, 1],  # Первая модель имеет больший вес\n",
    "    [1, 2, 1],  # Вторая модель имеет больший вес\n",
    "    [1, 1, 2],   # Третья модель имеет больший вес\n",
    "    [4, 1, 1],\n",
    "    [1, 4, 1],\n",
    "    [1, 1, 4],\n",
    "    [4, 1, 4]\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier:\n",
      "accuracy is 0.87407\n",
      "precision is 0.87528\n",
      "recall is 0.87407\n",
      "\n",
      "Best VotingClassifier on Test Set:\n",
      "accuracy is 0.90237\n",
      "precision is 0.90544\n",
      "recall is 0.90237\n",
      "Best param: [4, 1, 4]\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(**best_params_svm)\n",
    "dt_model = DecisionTreeClassifier(**best_params_dt)\n",
    "rf_model = RandomForestClassifier(**best_params_rf)\n",
    "\n",
    "# Создание VotingClassifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('svm', svm_model),\n",
    "        ('dt', dt_model),\n",
    "        ('rf', rf_model)\n",
    "    ],\n",
    "    voting='soft',  # Используем soft voting (вероятности)\n",
    "    weights=[1, 1, 1]  # Веса моделей (можно менять)\n",
    ")\n",
    "\n",
    "# Обучение VotingClassifier\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Прогнозирование на валидационном наборе данных\n",
    "y_val_pred_voting = voting_clf.predict(X_valid)\n",
    "\n",
    "# Оценка метрик для VotingClassifier\n",
    "accuracy_voting = accuracy_score(y_valid, y_val_pred_voting)\n",
    "precision_voting = precision_score(y_valid, y_val_pred_voting, average='weighted')\n",
    "recall_voting = recall_score(y_valid, y_val_pred_voting, average='weighted')\n",
    "\n",
    "print(\"VotingClassifier:\")\n",
    "print(f\"accuracy is {accuracy_voting:.5f}\")\n",
    "print(f\"precision is {precision_voting:.5f}\")\n",
    "print(f\"recall is {recall_voting:.5f}\")\n",
    "print()\n",
    "\n",
    "# Подбор лучших весов\n",
    "best_accuracy = 0\n",
    "best_weights = None\n",
    "\n",
    "weights_range = [\n",
    "    [1, 1, 1],  # Все модели имеют одинаковый вес\n",
    "    [2, 1, 1],  # Первая модель имеет больший вес\n",
    "    [1, 2, 1],  # Вторая модель имеет больший вес\n",
    "    [1, 1, 2],   # Третья модель имеет больший вес\n",
    "    [4, 1, 1],\n",
    "    [1, 4, 1],\n",
    "    [1, 1, 4],\n",
    "    [4, 1, 4]\n",
    "\n",
    "]\n",
    "\n",
    "# Перебор различных весов\n",
    "for weights in weights_range:\n",
    "    voting_clf.set_params(weights=weights)\n",
    "    voting_clf.fit(X_train, y_train)\n",
    "    y_val_pred = voting_clf.predict(X_valid)\n",
    "    accuracy = accuracy_score(y_valid, y_val_pred)\n",
    "    \n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_weights = weights\n",
    "\n",
    "# Обучение модели с лучшими весами\n",
    "voting_clf.set_params(weights=best_weights)\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Прогнозирование на тестовом наборе данных\n",
    "y_test_pred = voting_clf.predict(X_test)\n",
    "\n",
    "# Оценка метрик на тестовом наборе данных\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
    "recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "print(\"Best VotingClassifier on Test Set:\")\n",
    "print(f\"accuracy is {accuracy_test:.5f}\")\n",
    "print(f\"precision is {precision_test:.5f}\")\n",
    "print(f\"recall is {recall_test:.5f}\")\n",
    "print(f\"Best param: {best_weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bagging classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using `BaggingClassifier` and `SVM` with the best parameters create an ensemble, try different values of the `n_estimators`, use `random_state=21`.\n",
    "2. Play with the other parameters.\n",
    "3. Calculate the `accuracy`, `precision`, and `recall` for the model with the best parameters (in terms of accuracy) on the test set (if there are several of them with equal values, choose the one with the higher precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86391\n",
      "Precision: 0.86966\n",
      "Recall: 0.86391\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(C=10, gamma='auto', probability=True, random_state=21, kernel='rbf')\n",
    "bc = BaggingClassifier(estimator=svc, n_estimators=10, random_state=21)\n",
    "bc.fit(X_train, y_train)\n",
    "y_pred = bc.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.5f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.5f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Иван\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.28015073 0.35990095 0.35992679        nan        nan 0.35531008\n",
      " 0.38128768 0.39055556 0.37940138 0.36548665 0.38498708 0.39795866\n",
      " 0.39518088 0.39704134 0.37104651 0.47216624 0.4638329  0.39426357\n",
      "        nan        nan 0.58350129 0.59091731 0.58999569 0.58907407\n",
      " 0.58255383 0.66602929 0.67347115 0.67255814 0.68367786 0.67812661\n",
      " 0.40630922        nan        nan        nan        nan 0.69387166\n",
      " 0.69944014 0.71429371 0.71429371 0.71521533 0.82093023 0.82650301\n",
      " 0.82556417 0.82555986 0.83113264]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best param: {'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 50, 'random_state': 21}\n",
      "Best score: 0.8311326442721791\n",
      "Accuracy: 0.88462\n",
      "Precision: 0.88941\n",
      "Recall: 0.88462\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_estimators': range(10, 60, 10),\n",
    "               \"max_features\": [0.1, 0.5, 1.0],\n",
    "               \"max_samples\": [0.1, 0.5, 1.0], \n",
    "               'random_state': [21]}\n",
    "\n",
    "gs = GridSearchCV(bc, param_grid, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "gs.fit(X_train, y_train)\n",
    "print(f'Best param: {gs.best_params_}')\n",
    "print(f'Best score: {gs.best_score_}')\n",
    "y_pred = gs.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.5f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.5f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Stacking classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. To achieve reproducibility in this case you will have to create an object of cross-validation generator: `StratifiedKFold(n_splits=n, shuffle=True, random_state=21)`, where `n` you will try to optimize (the details are below).\n",
    "2. Using `StackingClassifier` and the three models that you have recently trained, calculate the `accuracy`, `precision` and `recall` on the validation set, try different values of `n_splits` `[2, 3, 4, 5, 6, 7]` in the cross-validation generator and parameter `passthrough` in the classifier itself,\n",
    "3. Calculate the `accuracy`, `precision`, and `recall` for the model with the best parameters (in terms of accuracy) on the test set (if there are several of them with equal values, choose the one with the higher precision). Use `final_estimator=LogisticRegression(solver='liblinear')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('svm', svm_model), ('dt', dt_model), ('rfc', rf_model)]\n",
    "results = []\n",
    "\n",
    "for n_splits in [2, 3, 4, 5, 6, 7]:\n",
    "    for passthrough in [True, False]:\n",
    "        cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=21)\n",
    "        stacking_model = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(solver='liblinear'), passthrough=passthrough)\n",
    "\n",
    "        accuracy_scores = []\n",
    "        precision_scores = []\n",
    "        recall_scores = []\n",
    "\n",
    "        for train_index, val_index in cv.split(X_train, y_train):\n",
    "            X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "            y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "            stacking_model.fit(X_train_fold, y_train_fold)\n",
    "            y_pred = stacking_model.predict(X_val_fold)\n",
    "\n",
    "            accuracy_scores.append(accuracy_score(y_val_fold, y_pred))\n",
    "            precision_scores.append(precision_score(y_val_fold, y_pred, average='weighted', zero_division=0)) # zero_division=0 чтобы избежать предупреждений\n",
    "            recall_scores.append(recall_score(y_val_fold, y_pred, average='weighted'))\n",
    "\n",
    "        avg_accuracy = np.mean(accuracy_scores)\n",
    "        avg_precision = np.mean(precision_scores)\n",
    "        avg_recall = np.mean(recall_scores)\n",
    "\n",
    "        # results[(n_splits, passthrough)] = {\n",
    "        #     'accuracy': avg_accuracy,\n",
    "        #     'precision': avg_precision,\n",
    "        #     'recall': avg_recall\n",
    "        # }\n",
    "        results.append((n_splits, passthrough, avg_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, True, np.float64(0.8506493506493507)), (2, False, np.float64(0.8478664192949907)), (3, True, np.float64(0.8701201898277108)), (3, False, np.float64(0.8664087485814506)), (4, True, np.float64(0.886802973977695)), (4, False, np.float64(0.880314608288586)), (5, True, np.float64(0.8998062015503876)), (5, False, np.float64(0.8979586563307494)), (6, True, np.float64(0.8933116076970826)), (6, False, np.float64(0.8961049037864681)), (7, True, np.float64(0.8998144712430427)), (7, False, np.float64(0.9007421150278293))]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Choose the best model in terms of accuracy (if there are several of them with equal values, choose the one with the higher precision).\n",
    "2. Analyze: for which weekday your model makes the most errors (in % of the total number of samples of that class in your full dataset), for which labname and for which users.\n",
    "3. Save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = VotingClassifier(estimators=estimators, voting='soft', weights = [4, 1, 4]).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecast = pd.DataFrame({\"predict\":best_model.predict(X_test)}, index= y_test.index)\n",
    "df_fit = pd.DataFrame({\"predict\":best_model.predict(X_train)}, index= y_train.index)\n",
    "df['forecast'] = pd.concat([df_fit, df_forecast])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Error'] = (df[\"forecast\"]!=df.dayofweek)*1\n",
    "error_analysis = df.groupby(['dayofweek']).agg(\n",
    "    total_samples=('Error', 'size'),\n",
    "    total_errors=('Error', 'sum')\n",
    ").reset_index()\n",
    "error_analysis['perc_error'] = (error_analysis.total_errors/error_analysis.total_samples).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>total_samples</th>\n",
       "      <th>total_errors</th>\n",
       "      <th>perc_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>32</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>271</td>\n",
       "      <td>52</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>104</td>\n",
       "      <td>20</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>356</td>\n",
       "      <td>64</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>274</td>\n",
       "      <td>50</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>149</td>\n",
       "      <td>26</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>396</td>\n",
       "      <td>68</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dayofweek  total_samples  total_errors  perc_error\n",
       "0          0            136            32        0.24\n",
       "5          5            271            52        0.19\n",
       "4          4            104            20        0.19\n",
       "6          6            356            64        0.18\n",
       "1          1            274            50        0.18\n",
       "2          2            149            26        0.17\n",
       "3          3            396            68        0.17"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_analysis.sort_values(by = 'perc_error', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uid_user_23    0.50\n",
       "uid_user_6     0.33\n",
       "uid_user_17    0.32\n",
       "uid_user_18    0.29\n",
       "uid_user_22    0.29\n",
       "uid_user_16    0.28\n",
       "uid_user_29    0.25\n",
       "uid_user_15    0.24\n",
       "uid_user_3     0.24\n",
       "uid_user_14    0.23\n",
       "uid_user_27    0.22\n",
       "uid_user_4     0.21\n",
       "uid_user_2     0.21\n",
       "uid_user_20    0.19\n",
       "uid_user_24    0.18\n",
       "dayofweek      0.18\n",
       "uid_user_26    0.17\n",
       "uid_user_25    0.16\n",
       "uid_user_31    0.15\n",
       "uid_user_1     0.15\n",
       "uid_user_10    0.14\n",
       "uid_user_19    0.13\n",
       "uid_user_28    0.13\n",
       "uid_user_30    0.13\n",
       "uid_user_12    0.12\n",
       "uid_user_13    0.12\n",
       "uid_user_21    0.09\n",
       "uid_user_0     0.00\n",
       "uid_user_11    0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((df[df.Error == 1].iloc[:,2:31].sum()/df.iloc[:,2:31].sum()).round(2)).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labname_lab03       1.00\n",
       "labname_lab03s      1.00\n",
       "labname_lab05s      0.25\n",
       "labname_laba06      0.23\n",
       "labname_laba04s     0.22\n",
       "labname_laba04      0.21\n",
       "labname_laba06s     0.20\n",
       "labname_project1    0.18\n",
       "labname_code_rvw    0.18\n",
       "labname_laba05      0.16\n",
       "labname_lab02       0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((df[df.Error == 1].iloc[:,33:-2].sum()/df.iloc[:,33:-2].sum()).round(2)).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../model/best_model_ex03.joblib']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(best_model, '../model/best_model_ex03.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
